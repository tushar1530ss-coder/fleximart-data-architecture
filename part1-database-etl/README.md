Part 1 â€“ ETL Pipeline & Data Quality (MySQL)
ğŸ“Œ Overview

Part 1 of this project focuses on building a robust ETL (Extract, Transform, Load) pipeline for an e-commerce system using raw CSV datasets.
The goal is to identify data quality issues, clean and standardize the data, and load it into a relational database (MySQL).

This part simulates real-world production data challenges such as missing values, duplicates, and inconsistent formats.

ğŸ“‚ Input Datasets
Dataset	Description
customers_raw.csv	Customer master data
products_raw.csv	Product master data
sales_raw.csv	Transactional sales data
ğŸ§¹ Data Quality Challenges
Customers Data

Missing email addresses

Duplicate customer records

Inconsistent phone number formats

Mixed date formats

Inconsistent city casing

Products Data

Missing prices

Missing stock quantities

Inconsistent category values

Extra spaces in product names

Sales Data

Duplicate transactions

Missing customer IDs

Missing product IDs

Multiple date formats

ğŸ” Data Quality Checks

Before loading, the following checks are performed:

Duplicate record detection

Missing value identification

Date format validation and normalization

Category standardization

Phone number normalization

Referential integrity validation for sales data

ğŸ“„ Detailed findings are documented in:
reports/data_quality_report.txt

ğŸ”„ ETL Pipeline Flow
1ï¸âƒ£ Extract

Read raw CSV files using Python

Load data into pandas DataFrames

2ï¸âƒ£ Transform

Remove duplicate records

Standardize date formats to YYYY-MM-DD

Normalize phone numbers

Clean and trim text fields

Normalize category values

Handle missing and null values

Validate foreign key relationships

3ï¸âƒ£ Load

Load cleaned data into MySQL

Store customers, products, and sales in relational tables

ğŸ—„ï¸ Database Design

Database: ecommerce_db

Tables

customers

products

sales

Refer to:
ğŸ“˜ schema_documentation.md for full schema details.

ğŸ› ï¸ Technologies Used

Python (pandas)

MySQL

SQL

Git

â–¶ï¸ How to Run Part 1

Clone the repository

git clone <repo-url>
cd part1-etl-mysql


Create database and tables

source sql/create_tables.sql;


Run ETL pipeline

python etl/etl_pipeline.py


Verify loaded data

SELECT COUNT(*) FROM customers;
SELECT COUNT(*) FROM products;
SELECT COUNT(*) FROM sales;

ğŸ“ˆ Outcomes

Raw data transformed into clean, analytics-ready tables

Improved data consistency and integrity

Clear documentation of data quality issues

Production-style ETL workflow

ğŸ”® Future Improvements

Add automated data validation checks

Introduce incremental loads

Implement Airflow for scheduling

Add indexes for performance optimization

ğŸ‘¤ Author

Tushar Singh
